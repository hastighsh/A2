{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Import the adult dataset from the ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(adult.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Take a quick look at the data structure (i.e., X) using .head(), .info(), .describe(), and .shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use head() to look at the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use info() to get a quick description of the data\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use .describe() method to see a summary of the numerical attributes\n",
    "X.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.1: Plot a histogram of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram of the data using hist()\n",
    "X.hist(figsize=(20, 16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: There are missing values in this dataset that are entered as ?, check for the number of these missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of the missing elements denoted by ?\n",
    "X[X == '?'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the ? with null value and showing the data using info()\n",
    "X = X.replace('?', np.nan)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Create and apply a preprocessing pipeline to:\n",
    "1. Fill in the missing numerical values with the mean using a SimpleImputer.\n",
    "2. Scale the numerical columns using StandardScaler. Do not scale the target.\n",
    "3. Fill in the missing categorical values with the most_frequent value using SimpleImputer.\n",
    "4. Encode the categorical columns using OneHotEncoder. Do not encode the target.\n",
    "- Display your pipeline.\n",
    "- Print X_prepared.shape.\n",
    "Tips:\n",
    "- If you are facing an issue with the preprocessing pipeline producing a sparse matrix, pass a “sparse_output=False” option to the OneHotEncoder in the pipeline, i.e., OneHotEncoder(sparse_output=False)\n",
    "- X_prepared.shape should be (48842, 105) at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cat and num columns\n",
    "# Get a list of column names from the 'X' DataFrame that are of numerical data types.\n",
    "# Get a list of column names from the 'X' DataFrame that are not of numerical data types.\n",
    "\n",
    "num_cols = X.select_dtypes(include='number').columns.to_list()\n",
    "cat_cols = X.select_dtypes(exclude='number').columns.to_list()\n",
    "\n",
    "print(num_cols)\n",
    "\n",
    "print(cat_cols)\n",
    "\n",
    "# Create pipelines for numeric and categorical columns\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "\n",
    "# Use ColumnTransformer to set the estimators and transformations\n",
    "\n",
    "preprocessing = ColumnTransformer([('num', num_pipeline, num_cols),\n",
    "                                   ('cat', cat_pipeline, cat_cols)],\n",
    "                                    remainder='passthrough'\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the numerical columns\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the pipeline\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the pipeline to the dataset\n",
    "X_prepared = preprocessing.fit_transform(X)\n",
    "X_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Check the target value_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using value_count() to get the count of differnet targets\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Remove the period at the end of the >50K. and <=50K. i.e., replace all instances that are <=50K. with <=50K , and replace all the instances that are >50K. with >50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the values in the target data with the desired value\n",
    "y = y.replace('<=50K.', '<=50K')\n",
    "y = y.replace('>50K.', '>50K')\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Split the data into 80% training set and 20% testing set, print the shape of X_train, X_test, y_train, y_test in one command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data by choosing 20% of the data be the test data and the rest training set (80%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_prepared, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: Train a svm model (svc) to predict if the income of the adult exceeds 50K on the training set using: kernel = poly, gamma = 1, and C =0.1. Call your model model_svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the SVC function traing the data with Polynomial model, gamma = 1, C = 0.1\n",
    "model_svm = SVC(kernel='poly', C=0.1, gamma=1)\n",
    "model_svm.fit(X_train.iloc[:10000], y_train.iloc[:10000].values.ravel())\n",
    "model_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9.1: Test your model on the X_Test, and report the classification_report on the y_test and y_predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "y_predict = clf.predict(X_test)\n",
    "print(f'classification_report for C = 1')\n",
    "print (classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9.2: Display the confusion matrix of your test results using ConfusionMatrixDisplay.from_predictions(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10: Use GridSearchCV to find the best value of kernel, gamma, and C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10.1: Split the dataset into 60% training, 20% validation, and 20% testing. Use the code below to perform the split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data set into 40% validaton set and 60% training set\n",
    "X_train, X_validation_test, y_train, y_validation_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# splitting the training dataset (the initial  40%) into half, validation and test set (each 20% of the original dataset)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_validation_test, y_validation_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_validation.shape, y_validation.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10.2: Use the below code snippet to pass the following hyperparameters for the GridSearchCV to find the best ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code author luisguiserrano \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_parameters = {'kernel': ['rbf'],\n",
    "                  'C': [0.01, 0.1, 1 , 10],\n",
    "                  'gamma': [0.01, 1, 10]\n",
    "                }\n",
    "svm = SVC()\n",
    "svm_gs = GridSearchCV(estimator = svm,\n",
    "                      param_grid = svm_parameters)\n",
    "svm_gs.fit(X_train.iloc[:10000], y_train.iloc[:10000].values.ravel())\n",
    "\n",
    "svm_winner = svm_gs.best_estimator_\n",
    "svm_winner.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10.2: Check the svm winner parameters using svm_winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the vm number\n",
    "svm_winner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
